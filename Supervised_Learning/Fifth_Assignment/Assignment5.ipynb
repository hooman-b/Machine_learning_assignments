{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio assignment week 5\n",
    "\n",
    "## 1. SVC\n",
    "\n",
    "The Scikit-learn library provides different kernels for the Support Vector Classifier, e.g. `RBF` or `polynomial`.\n",
    "\n",
    "Based on the examples [in the accompanying notebook](../Exercises/E_LR_SVM.ipynb), create your own `SVC` class and configure it with different kernels to see if you are able to have it correctly separate the moon-dataset. You can also use a `precomputed` kernel. In addition, there are several parameters you can tune to for better results. Make sure to go through [the documentation](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html).\n",
    "\n",
    "**Hint**:\n",
    "\n",
    "- Plot the support vectors for understanding how it works.\n",
    "- Give arguments why a certain kernel behaves a certain way.\n",
    "\n",
    "## 2. Model Evaluation\n",
    "\n",
    "Classification metrics are important for measuring the performance of your model. Scikit-learn provides several options such as the `classification_report` and `confusion_matrix` functions. Another helpful option is the `AUC ROC` and `precision-recall curve`. Try to understand what these metrics mean and give arguments why one metric would be more important then others.\n",
    "\n",
    "For instance, if you have to predict whether a patient has cancer or not, the number of false negatives is probably more important than the number of false positives. This would be different if we were predicting whether a picture contains a cat or a dog – or not: it all depends on the context. Thus, it is important to understand when to use which metric.\n",
    "\n",
    "For this exercise, you can use your own dataset if that is eligable for supervised classification. Otherwise, you can use the [breast cancer dataset](https://www.kaggle.com/datasets/yasserh/breast-cancer-dataset) which you can find on assemblix2019 (`/data/datasets/DS3/`). Go through the data science pipeline as you've done before:\n",
    "\n",
    "1. Try to understand the dataset globally.\n",
    "2. Load the data.\n",
    "3. Exploratory analysis\n",
    "4. Preprocess data (skewness, normality, etc.)\n",
    "5. Modeling (cross-validation and training)\n",
    "6. **Evaluation**\n",
    "\n",
    "Create and train several `LogisticRegression` and `SVM` models with different values for their hyperparameters. Make use of the model evaluation techniques that have been described during the plenary part to determine the best model for this dataset. Accompany you elaborations with a conclusion, in which you explicitely interpret these evaluation and describe why the different metrics you are using are important or not. Make sure you take the context of this dataset into account.\n",
    "\n",
    "# Data\n",
    "for this Assignment I found two great dataset, one of them is [Cancer Dataset](https://www.kaggle.com/datasets/erdemtaha/cancer-data) and the other one is [Star Classification Dataset](https://www.kaggle.com/datasets/fedesoriano/stellar-classification-dataset-sdss17). I had difficulty deciding between the star dataset, which involves multi-class classification, and the cancer dataset, which is a binary classification problem. However, for this week's assignment, I decided to work on the Cancer Dataset since I worked another physics dataset for second assignment. I may explore the star classification dataset in the future, particularly for unsupervised classification section. \n",
    "\n",
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general libraries\n",
    "import yaml\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspired by https://fennaf.gitbook.io/bfvm22prog1/data-processing/configuration-files/yaml\n",
    "\n",
    "def configReader():\n",
    "    \"\"\"\n",
    "    explanation: This function open config,yaml file \n",
    "    and fetch the gonfigue file information\n",
    "    input: ...\n",
    "    output: configue file\n",
    "    \"\"\"\n",
    "    with open(\"config.yaml\", \"r\") as inputFile:\n",
    "        config = yaml.safe_load(inputFile)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dataframe_maker(config):\n",
    "    file_directory, file_name = config.values()\n",
    "    os.chdir(file_directory)\n",
    "    df = pd.read_csv(file_name).drop('Unnamed: 32', axis=1)\n",
    "    return df\n",
    "df = dataframe_maker(configReader())\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset consists of 569 samples with 32 features. In my opinion, during the inspection phase, one of the primary objectives is to become acquainted with various aspects of the dataset. Therefore, I conducted some research on the different features of this dataset and compiled a list of them below. The features primarily covers the following parameters:\n",
    "\n",
    "**concavity**: This concept pertains to the presence of concave areas on the surface of a tumor. A greater number of concave points along the nuclear border is associated with a higher probability of malignancy. The severity and quantity of these concave points demonstrate a positive correlation with the diagnosis.[<a href=\"https://rpubs.com/Kevin_Nguyen_Tran/662211\" target=\"_blank\">link</a>]\n",
    "\n",
    "**compactness**: Tumor compactness is defined as the ratio of the tumor's volume to its surface area. This feature is closely tied to the spatial configuration of tumors, and as a result, we can expect to observe some dependencies between tumor compactness and other spatial features. [<a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5352371/\" target=\"_blank\">link</a>]\n",
    "\n",
    "**Fractal Dimension**:  Fractal dimension analysis is a computational image processing technique utilized to evaluate the level of complexity within patterns. The technique, described comprehensively in the provided link, demonstrates its effectiveness in enhancing the histopathological diagnosis of breast cancer. [<a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8087740/\" target=\"_blank\">link</a>] \n",
    "\n",
    "**symmetry**: In typical normal tissues, cell division typically produces identical or nearly identical pairs of daughter cells. However, in the context of cancer, cell division often follows an asymmetric pattern, characterized by a series of events that break the symmetry. If you're interested in learning more about this topic, there is an informative article available that provides further insights. [<a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5837760/\" target=\"_blank\">link</a>]\n",
    "\n",
    "**smoothness**: Benign masses typically exhibit smooth, round, and well-defined boundaries, in contrast to malignant tumors that often display spiculated, rough, and indistinct edges. Various methods can be employed to quantify tumor smoothness, including the neighboring gray-level dependence matrix (NGLDM) method and the peak-variance method. [<a href=\"https://pubmed.ncbi.nlm.nih.gov/1623493/\" target=\"_blank\">link</a>] [<a href=\"https://my.clevelandclinic.org/health/diseases/22121-benign-tumor\" target=\"_blank\">link</a>]\n",
    "\n",
    "**radius, area, and perimeter**: The spatial configuration of a tumor plays a crucial role in evaluating its malignancy. A commonly used approach to determine the volume and perimeter of subcutaneous tumors involves measuring the length and width of the tumor using a caliper. This method assumes that the tumor has an ellipsoidal shape and that its height is equal to its width. By applying the formula for the volume and perimeter of an ellipsoid, these measurements can be used to estimate these parameters accurately.[<a href=\"https://biopticon.com/resources/tumor-volume-measurements-by-calipers/\" target=\"_blank\">link</a>]\n",
    "\n",
    "**cancer texture**: The topic of cancer texture remains a subject of debate within scientific societies. While tumors may appear hard to the touch externally, research has revealed that individual cells within the tissue exhibit non-uniform rigidity and can even display variations in softness throughout the tumor. Texture analysis is employed to quantitatively assess texture characteristics. By examining the spatial variation in pixel intensities, it captures and quantifies intuitive qualities such as roughness, smoothness, silkiness, or bumpiness associated with the tumor's appearance. [<a href=\"https://cos.northeastern.edu/news/cancer-tumors-arent-always-as-tough-as-they-seem/\" target=\"_blank\">link</a>] [<a href=\"https://www.mathworks.com/help/images/texture-analysis-1.html\" target=\"_blank\">link</a>]\n",
    "\n",
    "# Inspecting Dataset\n",
    "Similar to all the privious notebooks, I should metioned that this section is one of the most important part of datascience pipeline. Consequently, one should be cautious to find all the abnormaliries and characteristics of a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspecting_data(df):\n",
    "\n",
    "    # find the shape of data\n",
    "    print(f'dataset has {df.shape[0]} observations, and {df.shape[1]} variables\\n')\n",
    "\n",
    "    # finding the information of this dataset\n",
    "    print(f'{df.info()}\\n')\n",
    "\n",
    "    # extract the number of null values of the dataset\n",
    "    null_values = df.isnull().sum().sum()\n",
    "    print(f'the total number of null values in this dataset is {null_values}\\n')\n",
    "\n",
    "    # find whether the number of unique ids is equel to the number of observations\n",
    "    if df.id.unique().shape[0] == df.shape[0]:\n",
    "        print(f'the number of unique IDs is {df.shape[0]}, which it is equal to the number of observations\\n')\n",
    "    \n",
    "    # find the distributaion of the datapoints in the label column\n",
    "    member_numbers = df.diagnosis.value_counts()\n",
    "    print(f'number of members in each diagnosis category')\n",
    "    print(f'{member_numbers}\\n')\n",
    "    print(f'Benign (B): {(member_numbers[0] / df.shape[0]).round(3)}%')\n",
    "    print(f'Malignant (M): {(member_numbers[1] / df.shape[0]).round(3)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 569 observations, and 32 variables\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.4+ KB\n",
      "None\n",
      "\n",
      "the total number of null values in this dataset is 0\n",
      "\n",
      "the number of unique IDs is 569, which it is equal to the number of observations\n",
      "\n",
      "number of members in each diagnosis category\n",
      "diagnosis\n",
      "B    357\n",
      "M    212\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Benign (B): 0.627%\n",
      "Malignant (M): 0.373%\n"
     ]
    }
   ],
   "source": [
    "inspecting_data(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the data inspection phase, it was observed that the dataset consists of 30 float features, one integer column representing the ID, and a categorical column containing the labels. One of the most important characteristics of this dataset is the presence of data imbalance. Specifically, the benign group constitutes two-thirds of the total datapoints, while the malignant cases represent only one-third of the dataset. however, the classification methods will initially be implemented without addressing this concern, and the subsequent step will involve tackling the data imbalance and re-implementing the classification methods with the appropriate adjustments. With this manner one can see the effect of the data imbalance in the outcome of the classification methods. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
