{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio assignment week 6\n",
    "\n",
    "# 1. Decision Trees and Naive bayes\n",
    "The scikit-learn library provides different parameters for decision trees and naive bayes. \n",
    "\n",
    "Based on the last code example [in the accompanying notebook](../Exercises/E_DT_NB.ipynb), add several new models to the `classifiers` variable. These models should have different parameters. For instance, create a new decision tree with a max depth of 1. Another possibility is to add different datasets or add noise.\n",
    "\n",
    "Try to understand why some models behave differently than others. Give arguments what influences model performance and why.\n",
    "\n",
    "# 2. Decision Tree Evaluation\n",
    "As shown in the [in the accompanying notebook](../Exercises/E_DT_NB.ipynb) it is possible to visualize the decision tree. \n",
    "\n",
    "For this exercise, you can use your own dataset if that is eligable for supervised classification. Otherwise, you can use the [breast cancer dataset](https://www.kaggle.com/datasets/yasserh/breast-cancer-dataset) which you can find on assemblix2019 (`/data/datasets/DS3/`). Go through the data science pipeline as you've done before:\n",
    "\n",
    "1. Try to understand the dataset globally.\n",
    "2. Load the data.\n",
    "3. Exploratory analysis\n",
    "4. Preprocess data (skewness, normality, etc.)\n",
    "5. Modeling (cross-validation and training)\n",
    "6. Evaluation\n",
    "7. **Explanation**\n",
    "\n",
    "Explain how the decision tree behaves under certain circumstances. What features seem important and how are the decisions made?\n",
    "\n",
    "## Dataset\n",
    "It is not fun to use the same dataset each time for each excersize :D. Consequently, I started to search for a fun and perfect dataset for this excercize (of course I participate in resit, and this is the reason that I have enough time to do this :D ). During my exploration of the concept of Decision Trees, I came across two interesting links (<a href=\"https://towardsdatascience.com/decision-trees-in-machine-learning-641b9c4e8052\" target=\"_blank\">tds-link</a> and <a href=\"https://en.wikipedia.org/wiki/Sinking_of_the_Titanic\" target=\"_blank\">wiki</a>) that caught my attention. Upon skimming through the wiki link, I stumbled upon a section called \"Casualties and survivors,\" which provided detailed information about the number of saved and lost passengers based on their gender and class. This dataset was sourced from an article written by L. Mersey in 1912 [1]. I found it intriguing that the author of the wiki link employed a treemap to categorize passengers, resulting in valuable insights into the casualties of this catastrophic event. Additionally, the tds-link utilized Decision Trees to classify the casualties and survivors based on their gender and age.Consequently, I found this topic fascinating to work on and present my own Decision tree model to describe the casualty of this catasrophic event. The Titanic dataset is extracted from this <a href=\"https://www.kaggle.com/datasets/vinicius150987/titanic3?resource=download\" target=\"_blank\">Kaggle</a> link.\n",
    "\n",
    "[1] Mersey, L. (1999). The Loss of the Titanic, 1912. London: Stationery Office.\n",
    "\n",
    "Thus, here I will delve into this dataset to extract the most reliable model for the number of lost and survived passengers. \n",
    "\n",
    "Like always, one can beging wit loading the data.\n",
    "\n",
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Modules\n",
    "import yaml\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import graphviz\n",
    "import time\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Dataset module\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons, make_circles\n",
    "\n",
    "# preprocessing modules\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Classification modules\n",
    "from sklearn import tree\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Metrics modules\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Model selection modules\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspired by https://fennaf.gitbook.io/bfvm22prog1/data-processing/configuration-files/yaml\n",
    "\n",
    "def configReader():\n",
    "    \"\"\"\n",
    "    explanation: This function open config,yaml file \n",
    "    and fetch the gonfigue file information\n",
    "    input: ...\n",
    "    output: configue file\n",
    "    \"\"\"\n",
    "    with open(\"config.yaml\", \"r\") as inputFile:\n",
    "        config = yaml.safe_load(inputFile)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
       "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
       "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
       "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "       age  sibsp  parch  ticket      fare    cabin embarked boat   body  \\\n",
       "0  29.0000      0      0   24160  211.3375       B5        S    2    NaN   \n",
       "1   0.9167      1      2  113781  151.5500  C22 C26        S   11    NaN   \n",
       "2   2.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "3  30.0000      1      2  113781  151.5500  C22 C26        S  NaN  135.0   \n",
       "4  25.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dataframe_maker(config):\n",
    "    file_directory, file_name = config.values()\n",
    "    os.chdir(file_directory)\n",
    "    df = pd.read_excel(file_name)#.drop('Unnamed: 32', axis=1)\n",
    "    return df\n",
    "df = dataframe_maker(configReader())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset consists of 1309 samples (passengers) and 14 features. Although each feature has the potential to influence the model's outcome, some of them may not significantly impact the model's functionality. Therefore, understanding the nature of each feature becomes crucial for the subsequent steps in the data-science pipeline. This knowledge empowers researchers to discern whether a feature holds importance in the analysis.  Thus, all the features will be described in the following paragraphs.\n",
    "\n",
    "1. **pclass**: presents ticket classes, a potentially significant feature that could have influenced the chances of survival. It is plausible that individuals from higher classes had a better chance of surviving, making this feature relevant for the analysis.\n",
    "\n",
    "2. **survived**: shows the labels that whether a passenger lost his/her life or survived from this disastorous event.\n",
    "\n",
    "3. **name**: contains the names of the passengers.\n",
    "\n",
    "4. **sex**: includes the gender of the passengers, which can significantly influence the model's performance. During emergency conditions, women are often prioritized for protection, making this feature highly relevant and potentially impactful on the model's predictions.\n",
    "\n",
    "5. **age**: This variable represents the age of the passengers, and once again, it can significantly impact the model's outcome. During emergency conditions, children are often given priority for protection, making this feature particularly relevant for predicting survival rates.\n",
    "\n",
    "6. **sibsp**: is the number of siblings and spouse. It can have a slight effect on the outcome of the model. Maybe people with higher number of sibsp had less chance of surviving.\n",
    "\n",
    "7. **parch**: this number preents the number of parents and children. This parameter is quite similar to privious one (sibsp).\n",
    "\n",
    "8. **ticket**: contains the number of passengers' tickets. It seems irrelevant to the topic.\n",
    "\n",
    "9. **fare**: includes the price of the tickets, which can be useful for classifying passengers based on their socio-economic status. Higher ticket prices might indicate a higher social class, while lower prices might correspond to a lower class. This feature can be valuable in categorizing passengers according to their economic standing.\n",
    "\n",
    "10. **cabin**: consists of information about the numbers of cabins for which passengers paid. This feature could be significant as passengers from cabins near the deck might have had an advantage, reaching the surface of the ship more quickly, which could have increased their chances of survival.\n",
    "\n",
    "11. **embarked**: includes the ports in which passengers are get into the ship.\n",
    "\n",
    "12. **boat**: consists of the boats' codes with which some of the passengers survived.\n",
    "\n",
    "13. **body**: contains the body numbers if did not survive and body was recovered. <a href=\"https://github.com/awesomedata/awesome-public-datasets/issues/351\" target=\"_blank\">link</a> \n",
    "\n",
    "14. **home.dest**: contains the home destination of all the the passengers.\n",
    "\n",
    "Next part is the most vital part of this project which is **Data Inspection**.\n",
    "\n",
    "### Data Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Naive Bayes \n",
    "\n",
    "During the Corona pandemic, seven roommates in a student house did a Corona test. The table below show the data of these students: whether they experiences shivers, had a running nose, or had a headache. The test result is also shown.\n",
    "\n",
    "Roommate | shivers | running nose | headache | test result\n",
    "--|--|--|--|--\n",
    "1 | Y | N | No | Negative\n",
    "2 | N | N | Mild | Negative\n",
    "3 | Y | Y | No | Positive\n",
    "4 | N | Y | No | Negative\n",
    "5 | N | N | Heavy | Positive\n",
    "6 | Y | N | No | Negative\n",
    "7 | Y | Y | Mild | Positive\n",
    "\n",
    "Explain why it is not useful to include the column 'Roommate' in a classification procedure.\n",
    "\n",
    "Train a [Categorical Naive Bayes](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.CategoricalNB.html) classifier on this dataset, where the Test Results are your classes and the other features the data. For this to work, you'll need [Pandas `get_dummies`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) to transform the nominal data into something that sklearn can work with. Use all seven rows in your training.\n",
    "\n",
    "If you let your fitted classifier predict the test results (based on all the data), you will (hopefully) see that the prediction for observation number 5 (1-based) is wrong (it predicts Negative while the actual value is Positive). Show by manual calculation that the prediction for this instance is indeed higher ($p=0.527$) for the Negative class than for the Positive class.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
