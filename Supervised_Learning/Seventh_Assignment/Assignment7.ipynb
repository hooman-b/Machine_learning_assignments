{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio assignment week 7\n",
    "\n",
    "## 1. Bagging vs Boosting\n",
    "The scikit-learn library provides several options for bagging and boosting. It is possible to create your own boosting model based on a base model. For instance, you can create a tree based bagging model. In addition, scikit-learn provides AdaBoost. For XGBoost it is best to use the xgboost library.\n",
    "\n",
    "Based on the theory in the [accompanying notebook](../Exercises/E_BAGGING_BOOSTING.ipynb), create a bagging, boosting and dummy classifier. Test these classifiers on the [breast cancer dataset](https://www.kaggle.com/datasets/yasserh/breast-cancer-dataset). Go through the data science pipeline as you've done before:\n",
    "\n",
    "1. Try to understand the dataset globally.\n",
    "2. Load the data.\n",
    "3. Exploratory analysis\n",
    "4. Preprocess data (skewness, normality, etc.)\n",
    "5. Modeling (cross-validation and training). (**Create several bagging classifiers with different estimators**.)\n",
    "6. Evaluation (**Use the evaluation methods as described in the previous lessons. Then compare the different models**.)\n",
    "7. Try to understand why some methods perform better than others. Try different configurations for your bagging and boosting models."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
